# ğŸ¤– TECHGESTURESPEAK: Arduino-Based Glove for Translating Sign Language into Speech

**TECHGESTURESPEAK** is an Arduino-based wearable technology designed to **translate sign language gestures into spoken words in real time**. This system empowers individuals with **speech and hearing impairments** to communicate seamlessly with those who may not understand sign language. It is a **low-cost**, **portable**, and **user-friendly** solution that combines **hardware prototyping** and **embedded systems programming** to create a powerful assistive communication device.

---

## ğŸ“ Table of Contents

- [ğŸ¯ Project Overview](#-project-overview)
- [ğŸ§  Abstract](#-abstract)
- [ğŸ”§ Features](#-features)
- [ğŸ› ï¸ Hardware Architecture](#ï¸-hardware-architecture)
- [ğŸ§° Technologies Used](#-technologies-used)
- [ğŸ’¡ How It Works](#-how-it-works)
- [ğŸ“¦ System Block Diagram](#-system-block-diagram)
- [ğŸš€ Setup & Usage](#-setup--usage)
- [ğŸ” Results & Analysis](#-results--analysis)
- [ğŸ“Š Accuracy Testing](#-accuracy-testing)
- [âš™ï¸ Challenges & Limitations](#ï¸-challenges--limitations)
- [ğŸŒ± Future Enhancements](#-future-enhancements)
- [ğŸ“š References](#-references)
- [ğŸ‘¥ Team Members](#-team-members)
- [ğŸ“¬ Contact](#-contact)
- [ğŸ“„ License](#-license)

---

## ğŸ¯ Project Overview

The project aims to bridge the communication gap between sign language users and non-signers using an **Arduino Nano-powered glove**. The glove is embedded with **flex sensors** that detect finger movements and hand gestures. These gestures are then translated into spoken words using pre-recorded audio played via a **DFPlayer Mini module**.

This innovation can be used in:

- Hospitals and clinics ğŸ¥
- Schools and colleges ğŸ«
- Public transportation ğŸšŒ
- Customer service settings ğŸ§¾
- Daily personal communication ğŸ’¬

---

## ğŸ§  Abstract

TECHGESTURESPEAK provides a standalone solution for **gesture-to-speech translation**. Five flex sensors detect the bend of each finger and send analog signals to the Arduino Nano, which maps the gesture to a specific word or phrase. Upon recognition, the system triggers the **DFPlayer Mini** to play the corresponding audio through a speaker. The setup may also include a **16x2 LCD display** for text-based feedback.

This wearable system offers an **alternative to expensive, bulky, and non-portable assistive devices**, contributing to inclusive communication technology.

---

## ğŸ”§ Features

- âœ… Real-time gesture recognition and translation
- âœ… Fully offline system; no internet required
- âœ… Simple and modular circuit design
- âœ… LCD feedback for visual verification
- âœ… Speaker-based audible output
- âœ… Battery-powered and fully portable
- âœ… Easy to modify and expand for more gestures/languages

---

## ğŸ› ï¸ Hardware Architecture

| Component           | Purpose                                          |
|---------------------|--------------------------------------------------|
| **Arduino Nano**    | Main microcontroller that processes gestures     |
| **Flex Sensors**    | Detect finger movement and bending               |
| **DFPlayer Mini**   | Plays corresponding audio for recognized gestures|
| **8Î© Speaker**       | Outputs clear voice responses                    |
| **16x2 LCD Display**| Optional visual output for gestures              |
| **9V Battery**      | Powers the system for portability                |
| **Zero PCB**        | For final soldered circuit assembly              |
| **Breadboard**      | Used in prototyping stage                        |
| **Resistors & Wires** | Signal control and connectivity                |

---

## ğŸ§° Technologies Used

- âš¡ **Embedded C/C++** â€“ Arduino programming
- ğŸ§  **DFPlayer Mini Library** â€“ For easy audio file playback
- ğŸ§ª **Flex Sensor Integration** â€“ Gesture recognition
- ğŸ”Š **Voice Output** â€“ Using MP3/WAV files on microSD
- ğŸ”Œ **Serial Communication (UART)** â€“ For Arduino â†” DFPlayer data transfer
- ğŸ§¾ **LCD Integration** â€“ For gesture confirmation

---

## ğŸ’¡ How It Works

1. ğŸ–ï¸ **User performs a hand gesture**
2. ğŸ“ˆ Flex sensors detect finger bend levels
3. ğŸ§  Arduino interprets analog sensor input
4. ğŸ” Matches gesture to stored ID (e.g., `play(1)`)
5. ğŸ”Š Sends command to DFPlayer Mini
6. ğŸ—£ï¸ Audio phrase is played through speaker
7. ğŸ–¥ï¸ LCD optionally displays the text message

---

## ğŸ“¦ System Block Diagram

[Flex Sensors (Ã—5)] | [Arduino Nano] / [DFPlayer Mini] [LCD Display] | [Speaker] in Report detalied
## ğŸš§ System Architecture

- **Input**: 5 analog signals from flex sensors
- **Processing**: Arduino Nano reads and classifies gestures
- **Output**:
  - ğŸ§ Audio via DFPlayer Mini + speaker
  - ğŸ–¥ï¸ Text via LCD Display (optional)
- **Power**: 9V battery powering the entire system

---

## ğŸ”¬ Methodology

- âœ… Breadboard prototyping and sensor calibration
- âœ… Code development and gesture-to-audio mapping
- âœ… Audio pre-recording and SD card management
- âœ… PCB integration and final glove design
- âœ… Testing with real users and fine-tuning

---

## ğŸš€ Setup & Usage

### ğŸ”Œ Hardware Assembly
- Connect 5 flex sensors to A0â€“A4 analog pins on Arduino
- Connect DFPlayer Mini via TX (D10) and RX (D9)
- Load audio files (001.mp3, 002.mp3...) into microSD card
- Hook up speaker to DFPlayer Mini
- Power the system using 9V battery

### ğŸ§‘â€ğŸ’» Code Upload
- Open Arduino IDE
- Install `DFPlayer Mini` library
- Upload `TECHGESTURESPEAK.ino` sketch
- Adjust sensor threshold values for calibration

---

## ğŸ” Results & Analysis

- ğŸŸ¢ 95%+ accuracy in gesture detection under calibrated conditions
- â±ï¸ Response time < 500ms from gesture to audio output
- ğŸ”Š Clear voice output from 0.25W speaker
- ğŸ‘¥ Tested with 10+ sample gestures
- ğŸ” Real-time gesture-to-speech achieved with minimal delay
- ğŸ¯ High recognition accuracy for 10+ gestures
- ğŸ’¬ Positive user feedback on audio clarity and usability
- âœ… Fully portable, comfortable, and standalone

---

## ğŸ“Š Accuracy Testing

- âœ”ï¸ Each gesture was tested 20+ times with different hand sizes
- ğŸ“‰ Errors analyzed and thresholds fine-tuned
- ğŸ”„ Iterative improvement led to more robust detection
- ğŸ§ª Overall success rate: ~93% across multiple conditions

---

## âš™ï¸ Challenges & Limitations

| Challenge                     | Status          |
|------------------------------|-----------------|
| Sensor drift/variation       | Calibrated      |
| Hand size variability        | Adjusted thresholds |
| Serial delay (DFPlayer)      | Optimized code  |
| Complex gesture differentiation | Needs ML (future) |
| Flex sensor fragility        | Handled with care |

---

## ğŸŒ± Future Enhancements

- ğŸ§  Use **Machine Learning (ML)** for gesture recognition
- ğŸ”„ Add **dynamic gesture recognition**
- ğŸŒ Support **multi-language audio output**
- ğŸ“² Integrate with **mobile apps via Bluetooth**
- ğŸ‘Ÿ Use **stretchable electronics** for better comfort
- ğŸ’¬ Build **customizable user-defined gestures**
- ğŸ¤– Integrate **machine learning** for adaptive gesture recognition
- ğŸŒ Add **Bluetooth/Wi-Fi** for mobile app communication
- ğŸ§  Expand to recognize **dynamic gestures**
- ğŸ—£ï¸ Add support for **multiple languages and dialects**
- ğŸ’¡ Use **flexible OLED display** for better text visualization

---

## ğŸ“š References

- IEEE, Elsevier, and Springer publications on sign-language tech
- [DFPlayer Mini Datasheet](https://wiki.dfrobot.com/DFPlayer_Mini_MP3_Player_SKU_DFR0299)
- Arduino documentation
- Assistive Technology journals

---

## ğŸ‘¥ Team Members

| Name               | Roll Number |
|--------------------|-------------|
| **Madhu Alapaka**  | 21MIS7022   |
| Krishna Mohan P.   | 21MIS7005   |
| Lakshman Rohit     | 21MIS7012   |
| Praneetha B.       | 21MIS7015   |
| Kaarthikeya K.     | 21MIS7039   |
| Nikhilesh P.       | 21MIS7087   |

**Institution:** School of Computer Science and Engineering (SCOPE),  
**VIT-AP University, Amaravati**  
**Guide:** Prof. Divya Meena Sundaram

## ğŸ« Academic Contribution

- Developed under the **MTech Integrated Software Engineering** program at **VIT-AP University**
- Supervised by **Prof. Divya Meena Sundaram**, Head of Networking and Security
- Part of Engineering Clinic project (ECS ID: 240620)

---

## ğŸ“¬ Contact

**Madhu Alapaka**  
ğŸ“§ Email: [alapakamadhusudhanbabu786@gmail.com](mailto:alapakamadhusudhanbabu786@gmail.com)  
ğŸ”— LinkedIn: [linkedin.com/in/madhusudhan7022786](https://www.linkedin.com/in/madhusudhan7022786/)

---

## ğŸ“„ License
This project is intended for academic use and learning purposes.  
This project is open-source and licensed under the **MIT License**.  
Feel free to use, modify, or contribute with proper attribution.

---

> â€œTECHGESTURESPEAK is more than a gloveâ€”it's a voice for those who go unheard.â€



